From 1acc546c34254774b6f6d67a412e3d115fd6d739 Mon Sep 17 00:00:00 2001
From: sidex15 <24408329+sidex15@users.noreply.github.com>
Date: Thu, 26 Jun 2025 12:49:32 +0800
Subject: [PATCH] fs: namespace: revert sus_mount to v1.5.5

SUSFS v1.5.6-v1.5.7 introduced mount ID reordering optimizations. But since it's for GKI or a specific fix for some devices, in this device it could
cause more harm than good which it leaks mount-related detections.

For now revert the sus_mount mechanism to v1.5.5 as it's still okay and stable.
---
 fs/namespace.c | 104 ++++++++++++++++---------------------------------
 1 file changed, 33 insertions(+), 71 deletions(-)

diff --git a/fs/namespace.c b/fs/namespace.c
index 1b7af984965d..8f77673f83d1 100644
--- a/fs/namespace.c
+++ b/fs/namespace.c
@@ -43,6 +43,7 @@ static DEFINE_IDA(susfs_mnt_group_ida);
 static int susfs_mnt_id_start = DEFAULT_SUS_MNT_ID;
 static int susfs_mnt_group_start = DEFAULT_SUS_MNT_GROUP_ID;
 
+#define CL_ZYGOTE_COPY_MNT_NS BIT(24) /* used by copy_mnt_ns() */
 #define CL_COPY_MNT_NS BIT(25) /* used by copy_mnt_ns() */
 #endif
 
@@ -1153,11 +1154,6 @@ vfs_kern_mount(struct file_system_type *type, int flags, const char *name, void
 {
 	struct mount *mnt;
 	struct dentry *root;
-#ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-	struct mount *m;
-	struct mnt_namespace *mnt_ns;
-	int mnt_id;
-#endif	
 
 	if (!type)
 		return ERR_PTR(-ENODEV);
@@ -1200,24 +1196,10 @@ vfs_kern_mount(struct file_system_type *type, int flags, const char *name, void
 	mnt->mnt_parent = mnt;
 
 #ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-	// - If caller process is zygote, then it is a normal mount, so we calculate the next available 
-	//   fake mnt_id for this mount
+	// If caller process is zygote, then it is a normal mount, so we just reorder the mnt_id
 	if (susfs_is_current_zygote_domain()) {
-		mnt_ns = current->nsproxy->mnt_ns;
-			if (mnt_ns) {
-				get_mnt_ns(mnt_ns);
-				rcu_read_lock();
-				mnt_id = list_first_entry(&mnt_ns->list, struct mount, mnt_list)->mnt_id;
-				list_for_each_entry_rcu(m, &mnt_ns->list, mnt_list) {
-				if (m->mnt_id < DEFAULT_SUS_MNT_ID) {
-					mnt_id++;
-				}					
-			}
-			WRITE_ONCE(mnt->mnt.susfs_mnt_id_backup, READ_ONCE(mnt->mnt_id));
-			WRITE_ONCE(mnt->mnt_id, READ_ONCE(mnt_id));
-			rcu_read_unlock();
-			put_mnt_ns(mnt_ns);
-		}
+		mnt->mnt.susfs_mnt_id_backup = mnt->mnt_id;
+		mnt->mnt_id = current->susfs_last_fake_mnt_id++;
 	}
 #endif
 
@@ -1250,9 +1232,6 @@ static struct mount *clone_mnt(struct mount *old, struct dentry *root,
 	struct mount *mnt;
 	int err;
 #ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-	struct mount *m;
-	struct mnt_namespace *mnt_ns;
-	int mnt_id;
 	bool is_current_ksu_domain = susfs_is_current_ksu_domain();
 	bool is_current_zygote_domain = susfs_is_current_zygote_domain();
 
@@ -1261,11 +1240,9 @@ static struct mount *clone_mnt(struct mount *old, struct dentry *root,
 	 * - if caller process is KSU, consider the following situation:
 	 *     1. it is NOT doing unshare => call alloc_vfsmnt() to assign a new sus mnt_id
 	 *     2. it is doing unshare => spoof the new mnt_id with the old mnt_id
-	* - For the rest of caller process with sus old->mnt_id => call alloc_vfsmnt() to assign a new sus mnt_id
-	* - Important notes: Here we can't determine whether the unshare is called by zygisk or not,
-	*   so we can only patch out the unshare code in zygisk source code for now,
-	*   but at least we can deal with old sus mounts using alloc_vfsmnt()
-	*/
+	 * - If caller process is zygote and old mnt_id is sus => call alloc_vfsmnt() to assign a new sus mnt_id
+	 * - For the rest of caller process that doing unshare => call alloc_vfsmnt() to assign a new sus mnt_id only for old sus mount
+	 */
 	// Firstly, check if it is KSU process
 	if (unlikely(is_current_ksu_domain)) {
 		// if it is doing single clone
@@ -1280,8 +1257,18 @@ static struct mount *clone_mnt(struct mount *old, struct dentry *root,
 		}
 		goto bypass_orig_flow;
 	}
-	// Lastly, just check if old->mnt_id is sus
-	if (old->mnt_id >= DEFAULT_SUS_MNT_ID) {
+	// Secondly, check if it is zygote process and no matter it is doing unshare or not
+	if (likely(is_current_zygote_domain) && (old->mnt_id >= DEFAULT_SUS_MNT_ID)) {
+		/* Important Note: 
+		 *  - Here we can't determine whether the unshare is called zygisk or not,
+		 *    so we can only patch out the unshare code in zygisk source code for now
+		 *  - But at least we can deal with old sus mounts using alloc_vfsmnt()
+		 */
+		mnt = alloc_vfsmnt(old->mnt_devname, true, 0);
+		goto bypass_orig_flow;
+	}
+	// Lastly, for other process that is doing unshare operation, but only deal with old sus mount
+	if ((flag & CL_COPY_MNT_NS) && (old->mnt_id >= DEFAULT_SUS_MNT_ID)) {
 		mnt = alloc_vfsmnt(old->mnt_devname, true, 0);
 		goto bypass_orig_flow;
 	}
@@ -1343,27 +1330,10 @@ static struct mount *clone_mnt(struct mount *old, struct dentry *root,
 	mnt->mnt_parent = mnt;
 
 #ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-	// - If caller process is zygote, then it is a normal mount, so we calculate the next available
-	//   fake mnt_id for this mount, but there is one situation that the previous clone_mnt is not
-	//   yet attached to the current mnt_ns during copy_tree() so that it will fail to calculate
-	//   the correct fake mnt_id.
-	// - Currently we have a tmep fix for this in copy_tree(), but maybe not reliable for other devices
-	if (likely(is_current_zygote_domain) && !(flag & CL_COPY_MNT_NS)) {
-		mnt_ns = current->nsproxy->mnt_ns;
-			if (mnt_ns) {
-				get_mnt_ns(mnt_ns);
-				rcu_read_lock();
-				mnt_id = list_first_entry(&mnt_ns->list, struct mount, mnt_list)->mnt_id;
-				list_for_each_entry_rcu(m, &mnt_ns->list, mnt_list) {
-				if (m->mnt_id < DEFAULT_SUS_MNT_ID) {
-					mnt_id++;
-				}					
-			}
-			WRITE_ONCE(mnt->mnt.susfs_mnt_id_backup, READ_ONCE(mnt->mnt_id));
-			WRITE_ONCE(mnt->mnt_id, READ_ONCE(mnt_id));
-			rcu_read_unlock();
-			put_mnt_ns(mnt_ns);
-		}		
+	// If caller process is zygote and not doing unshare, so we just reorder the mnt_id
+	if (likely(is_current_zygote_domain) && !(flag & CL_ZYGOTE_COPY_MNT_NS)) {
+		mnt->mnt.susfs_mnt_id_backup = mnt->mnt_id;
+		mnt->mnt_id = current->susfs_last_fake_mnt_id++;
 	}
 #endif
 
@@ -2109,9 +2079,6 @@ struct mount *copy_tree(struct mount *mnt, struct dentry *dentry,
 					int flag)
 {
 	struct mount *res, *p, *q, *r, *parent;
-#ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-	bool is_current_zygote_domain = susfs_is_current_zygote_domain();
-#endif
 
 	if (!(flag & CL_COPY_UNBINDABLE) && IS_MNT_UNBINDABLE(mnt))
 		return ERR_PTR(-EINVAL);
@@ -2128,9 +2095,6 @@ struct mount *copy_tree(struct mount *mnt, struct dentry *dentry,
 	p = mnt;
 	list_for_each_entry(r, &mnt->mnt_mounts, mnt_child) {
 		struct mount *s;
-#ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-		int attach_mnt_count = 0;
-#endif
 
 		if (!is_subdir(r->mnt_mountpoint, dentry))
 			continue;
@@ -2163,18 +2127,7 @@ struct mount *copy_tree(struct mount *mnt, struct dentry *dentry,
 				goto out;
 			lock_mount_hash();
 			list_add_tail(&q->mnt_list, &res->mnt_list);
-			attach_mnt(q, parent, p->mnt_mp);
-#ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
-			// This is a temp fix to force re-assign the fake mnt_id for a specific mount during clone_mnt(),
-			// not sure what will happen on other devices.
-			if (is_current_zygote_domain &&
-				!(flag & CL_COPY_MNT_NS) &&
-				q->mnt_id < DEFAULT_SUS_MNT_ID)
-			{
-				attach_mnt_count++;
-				q->mnt_id += attach_mnt_count;
-			}
-#endif			
+			attach_mnt(q, parent, p->mnt_mp);			
 			unlock_mount_hash();
 		}
 	}
@@ -3369,6 +3322,10 @@ struct mnt_namespace *copy_mnt_ns(unsigned long flags, struct mnt_namespace *ns,
 #ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
 	// Always let clone_mnt() in copy_tree() know it is from copy_mnt_ns()
 	copy_flags |= CL_COPY_MNT_NS;
+	if (is_zygote_pid) {
+		// Let clone_mnt() in copy_tree() know copy_mnt_ns() is run by zygote process
+		copy_flags |= CL_ZYGOTE_COPY_MNT_NS;
+	}
 #endif
 	new = copy_tree(old, old->mnt.mnt_root, copy_flags);
 	if (IS_ERR(new)) {
@@ -3407,6 +3364,7 @@ struct mnt_namespace *copy_mnt_ns(unsigned long flags, struct mnt_namespace *ns,
 			p = next_mnt(p, old);
 	}
 #ifdef CONFIG_KSU_SUSFS_SUS_MOUNT
+	// current->susfs_last_fake_mnt_id -> to record last valid fake mnt_id to zygote pid
 	// q->mnt.susfs_mnt_id_backup -> original mnt_id
 	// q->mnt_id -> will be modified to the fake mnt_id
 
@@ -3422,6 +3380,10 @@ struct mnt_namespace *copy_mnt_ns(unsigned long flags, struct mnt_namespace *ns,
 			q->mnt_id = last_entry_mnt_id++;
 		}
 	}
+	// Assign the 'last_entry_mnt_id' to 'current->susfs_last_fake_mnt_id' for later use.
+	// should be fine here assuming zygote is forking/unsharing app in one single thread.
+	// Or should we put a lock here?
+	current->susfs_last_fake_mnt_id = last_entry_mnt_id;
 #endif
 
 	namespace_unlock();
